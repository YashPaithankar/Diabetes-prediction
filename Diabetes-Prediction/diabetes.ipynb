# Integrating and save model(Cnn Algo)

# Importing necessary libraries for CNN
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import pandas as pd
import numpy as np

# Load dataset
dataset = pd.read_csv('diabetes.csv')

# Preprocessing to replace zeros with NaN and fill with mean values
dataset[["Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI"]] = dataset[["Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI"]].replace(0, np.NaN) 
dataset["Glucose"].fillna(dataset["Glucose"].mean(), inplace=True)
dataset["BloodPressure"].fillna(dataset["BloodPressure"].mean(), inplace=True)
dataset["SkinThickness"].fillna(dataset["SkinThickness"].mean(), inplace=True)
dataset["Insulin"].fillna(dataset["Insulin"].mean(), inplace=True)
dataset["BMI"].fillna(dataset["BMI"].mean(), inplace=True)

# Splitting features and target
X = dataset.iloc[:, :-1].values  # all columns except the last one (Outcome)
Y = dataset.iloc[:, -1].values   # the last column (Outcome)

# Reshape input for CNN (CNN expects 4D input [batch_size, height, width, channels])
X = X.reshape(X.shape[0], X.shape[1], 1, 1)

# Scaling the features
sc = MinMaxScaler()
X = sc.fit_transform(X.reshape(X.shape[0], -1)).reshape(X.shape[0], 8, 1, 1)

# Convert target variable to categorical (one-hot encoding)
Y = to_categorical(Y)

# Splitting data into training and testing sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=dataset['Outcome'])

# CNN Model architecture
model = Sequential()

# Adding the first convolutional layer
model.add(Conv2D(32, kernel_size=(2, 1), activation='relu', input_shape=(8, 1, 1)))
model.add(MaxPooling2D(pool_size=(2, 1)))

# Adding the second convolutional layer
model.add(Conv2D(64, kernel_size=(2, 1), activation='relu'))
# Removed the second MaxPooling layer to prevent shrinking to negative dimensions

# Flattening the matrix into a vector
model.add(Flatten())

# Adding the fully connected layer
model.add(Dense(128, activation='relu'))

# Adding the output layer (2 classes for binary classification)
model.add(Dense(2, activation='softmax'))

# Compiling the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Training the model
model.fit(X_train, Y_train, epochs=50, batch_size=10, validation_data=(X_test, Y_test))

# Evaluating the model
loss, accuracy = model.evaluate(X_test, Y_test)
print(f"Test Accuracy: {accuracy * 100:.2f}%")

# Saving the model to a file
import pickle
with open('model_cnn.pkl', 'wb') as file:
    pickle.dump(model, file)

